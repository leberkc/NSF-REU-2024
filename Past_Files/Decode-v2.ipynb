{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63a9c7a",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "1. Keep sending messages until you receive a message with 1 dependency.  This corresponds to a row in the matrix that sums to 1\n",
    "2. Decode this message and store it in an array named \"decoded_message\"\n",
    "3. Using the column id for the decoded message, check the same column for all other rows.  If another row in the same column is \"1\" then that row contain the same message.\n",
    "4. Decrement the row sum value in the row_sum array to indicate it has 1 less dependency. Only decrement if you have decoded a message \n",
    "5. If the row_sum value is \"1\" after decrementing it means we can decode that row (i.e. message).  For example, if we receive symbol 10, which is a decoded message, and then receive symbol 4, the row_sum value for row 4 gets decremented by 1 and the new row_sum value for row 4 goes from 2 to 1.  This means we can decode row 4 since it now has a row_sum value = 1.\n",
    "6. Check if we have the symbol for that row in the sent_symbol array.  If the symbol is in the sent_symbol array, xor that symbol with the decoded message.\n",
    "7. If we do not have the symbol in the sent_symbol array, send more symbols\n",
    "8. If the row_sum value is 0 after decrementing, it means we have decoded the row based on decoding other rows and we dont need to send that symbol.  For example, if we received symbol 10 and symbol 4, we can xor symbol 10 and symbol 4 and get message 2.  Now, we have message 2 without having received symbol 2. Now, decrement all row_sum values for rows in columns that contain a 1 in columns 0,6 or 10 10 since 2: [0,6,10].\n",
    "\n",
    "Next we can xor message 2 and message 10 to get message 4.  Now, since we have message 2 and message 4 we can xor message 2 and message 4 to get message 0.  So, we can decode message 0 without receving symbol 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40ee6927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial dependencies: [2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 1]\n",
      "To send an encoded message, enter a token id between 0 to 10 or type q to quit: 10\n",
      "Token sent: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Number of times each token sent: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Row sum:  [2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Previous decoded token index:  0\n",
      "\n",
      "This is a plaintext message\n",
      "Decoded message: d\n",
      "Need to send more tokens!\n",
      "Decoded message index:  10\n",
      "Encoded message index:  2\n",
      "Flag:  1\n",
      "Updated row sum:  [2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "\n",
      "Next token to send:  4\n",
      "Row sum:  [2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Previous decoded token index:  10\n",
      "\n",
      "Flag:  3\n",
      "Updated row sum:  [2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "To send an encoded message, enter a token id between 0 to 10 or type q to quit: 4\n",
      "Token sent: [0, 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Number of times each token sent: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Row sum:  [2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Previous decoded token index:  10\n",
      "\n",
      "Xor 4 10\n",
      "Xor b'\\x08' d\n",
      "Save Xor result to:  2\n",
      "XOR b'\\x08' d\n",
      "Decoded message: [0, 0, 'l', 0, 0, 0, 0, 0, 0, 0, 'd']\n",
      "Decoded message index:  4\n",
      "Encoded message index:  2\n",
      "Flag:  2\n",
      "Updated row sum:  [1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "\n",
      "Next message to decode:  2\n",
      "Next token to send:  0\n",
      "Row sum:  [1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Previous decoded token index:  4\n",
      "\n",
      "Flag:  3\n",
      "Updated row sum:  [1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [0, 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "To send an encoded message, enter a token id between 0 to 10 or type q to quit: 0\n",
      "Token sent: [b'\\x03', 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Number of times each token sent: [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Row sum:  [1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1]\n",
      "Sent tokens:  [b'\\x03', 0, 0, 0, b'\\x08', 0, 0, 0, 0, 0, bytearray(b'd')]\n",
      "Previous decoded token index:  4\n",
      "\n",
      "Xor 0 4\n",
      "Xor b'\\x03' 0\n",
      "Save Xor result to:  2\n",
      "XOR b'\\x03' 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "encoding without a string argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 273\u001b[0m\n\u001b[0;32m    210\u001b[0m             check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m#            decoded_mesg = check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m#            print(\"Decoded message: \", decoded_mesg)\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m#            is_start_token = check_dependencies(row_sum, token_id, sent_token)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m#                    send_token(row_sum,token_id, decoded_message)\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[63], line 210\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m#            token_id = int(choice)\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m#            sent_token_count[token_id] = sent_token_count[token_id] + 1  # count number times each token sent\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m#            sent_token[token_id] = encoded_message[token_id]\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m#            print(\"Token sent:\", sent_token)\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m#            print(\"Number of times each token sent:\", sent_token_count)\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m#            print(\"Initial dependencies:\", row_sum)\u001b[39;00m\n\u001b[0;32m    209\u001b[0m             next_message_to_decode_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m      \n\u001b[1;32m--> 210\u001b[0m             check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
      "Cell \u001b[1;32mIn[63], line 111\u001b[0m, in \u001b[0;36mcheck_dependencies\u001b[1;34m(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext token to send: \u001b[39m\u001b[38;5;124m\"\u001b[39m, next_row_id)\n\u001b[1;32m--> 111\u001b[0m         check_dependencies(updated_row_sum, next_row_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Case 2. The token has to be xor'd with another already decoded message in the row\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# The second condition means there is 1 dependency and\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# we also have received the token so we can decode it.  1 dependency, if it's not plaintext implies\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# we already decoded a message in this row, so we can xor it with the token \u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m  (row_sum[token_id] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sent_token[token_id]):      \n",
      "Cell \u001b[1;32mIn[63], line 158\u001b[0m, in \u001b[0;36mcheck_dependencies\u001b[1;34m(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSent tokens: \u001b[39m\u001b[38;5;124m\"\u001b[39m, sent_token)\n\u001b[0;32m    157\u001b[0m     token_id, sent_token, prev_decoded_index \u001b[38;5;241m=\u001b[39m get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index)  \u001b[38;5;66;03m# Get another token\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Case 4. We havent found a row with 1 dependency so no tokens can be decoded.  \u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe cant decode.  Send another token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[63], line 142\u001b[0m, in \u001b[0;36mcheck_dependencies\u001b[1;34m(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext message to decode: \u001b[39m\u001b[38;5;124m\"\u001b[39m, next_message_to_decode_index)\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext token to send: \u001b[39m\u001b[38;5;124m\"\u001b[39m, next_row_id)\n\u001b[1;32m--> 142\u001b[0m         check_dependencies(updated_row_sum, next_row_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Case 3. We havent received the token yet. We need to get anohter token and check if it can be decoded\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# The only other way we can decode a token with dependency 1 which is not\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# plaintext is if we have already decoded a message in that row\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# In case 3 we have a row or token with 1 dependency but we have received the token yet\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (row_sum[token_id] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sent_token[token_id]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):  \n",
      "Cell \u001b[1;32mIn[63], line 158\u001b[0m, in \u001b[0;36mcheck_dependencies\u001b[1;34m(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSent tokens: \u001b[39m\u001b[38;5;124m\"\u001b[39m, sent_token)\n\u001b[0;32m    157\u001b[0m     token_id, sent_token, prev_decoded_index \u001b[38;5;241m=\u001b[39m get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index)  \u001b[38;5;66;03m# Get another token\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Case 4. We havent found a row with 1 dependency so no tokens can be decoded.  \u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe cant decode.  Send another token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[63], line 126\u001b[0m, in \u001b[0;36mcheck_dependencies\u001b[1;34m(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXor\u001b[39m\u001b[38;5;124m\"\u001b[39m, sent_token[token_id], decoded_message[prev_decoded_index])\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave Xor result to: \u001b[39m\u001b[38;5;124m\"\u001b[39m,next_message_to_decode_index)\n\u001b[1;32m--> 126\u001b[0m result \u001b[38;5;241m=\u001b[39m xor(sent_token, token_id, decoded_message, prev_decoded_index)  \n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# token_id is index of the most recent token sent\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# d_index is the index of the previous token sent that has already been decoded\u001b[39;00m\n\u001b[0;32m    129\u001b[0m decoded_message[next_message_to_decode_index] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdecode()\n",
      "Cell \u001b[1;32mIn[63], line 62\u001b[0m, in \u001b[0;36mxor\u001b[1;34m(sent_token, token_id, decoded_message, d_index)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXOR\u001b[39m\u001b[38;5;124m\"\u001b[39m, sent_token[token_id], decoded_message[d_index])\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#    result = bytes(a ^ b for (a,b) in zip(sent_token[token_id], decoded_message[d_index]))\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(a \u001b[38;5;241m^\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m (a,b) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sent_token[token_id], \u001b[38;5;28mbytearray\u001b[39m(decoded_message[d_index], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: encoding without a string argument"
     ]
    }
   ],
   "source": [
    "## message = ['h','e','l', 'l','o','','w','o','r','l','d,']\n",
    "encoded_message = [b'\\x03', b'\\x17', b'3', b'\\x03', b'\\x08', b'$', bytearray(b'W'), b'-', b'$', b'\\x00', bytearray(b'd')]\n",
    "xor_pairs = {0: [2, 4], 1: [1, 8], 2: [0, 6, 10], 3: [7, 9], 4: [2, 10], 5: [0, 9], 6: [6], 7: [0, 1], 8: [0, 3], 9: [3, 9], 10: [10]}\n",
    "\n",
    "num_tokens = len(encoded_message)\n",
    "sent_token_count = [0]*num_tokens\n",
    "sent_token = [0]*num_tokens\n",
    "decoded_message = [0]*num_tokens\n",
    "\n",
    "#print(len(sent_stoken_count))\n",
    "\n",
    "mat = [[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,],\n",
    " [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,],\n",
    " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,],\n",
    " [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,],\n",
    " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,],\n",
    " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,],\n",
    " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,],\n",
    " [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    " [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,],\n",
    " [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,],\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,]]\n",
    "\n",
    "# sum each row in matrix to compute number of dependencies for each encoded message\n",
    "\n",
    "row_sum  = list(map(sum, mat))\n",
    "#print(\"Initial dependency list:\", row_sum)\n",
    "\n",
    "    \n",
    "def decode(sent_token, token_id):\n",
    "    # Check token received is plaintext\n",
    "    if (sent_token[token_id].decode()):  \n",
    "        print(\"This is a plaintext message\")\n",
    "        \n",
    "#        decoded_message[token_id] = sent_token[token_id].decode()\n",
    "        messg = sent_token[token_id].decode()\n",
    "        return messg, token_id\n",
    "\n",
    "    else:\n",
    "        print(\"Send more tokens!\")\n",
    "        # we've already decoded another message in this row so we can decode this message if we've received the token\n",
    "#        if sent_token[token_id]:\n",
    "            # get the index of the other decoded message in this row so we can xor it with the token to decode \n",
    "            # this message.  We can get the decoded index from the decoded_message array\n",
    "\n",
    "    \n",
    "def get_index(next_row_id, mat, token_id):\n",
    "                \n",
    "            temp_row = mat[next_row_id]\n",
    "            decoded_message_index = token_id\n",
    "            print(\"Decoded message index: \", decoded_message_index)\n",
    "            temp_row[decoded_message_index] = 0\n",
    "#            print(temp_row.index(1))\n",
    "            encoded_message_index = temp_row.index(1)\n",
    "            print(\"Encoded message index: \", encoded_message_index)\n",
    "            return encoded_message_index, decoded_message_index\n",
    "\n",
    "            \n",
    "def xor(sent_token, token_id, decoded_message, d_index):\n",
    "    print(\"XOR\", sent_token[token_id], decoded_message[d_index])\n",
    "#    result = bytes(a ^ b for (a,b) in zip(sent_token[token_id], decoded_message[d_index]))\n",
    "    result = bytes(a ^ b for (a,b) in zip(sent_token[token_id], bytearray(decoded_message[d_index], 'utf-8')))\n",
    "    return result\n",
    "    \n",
    "def update_dependencies(row_sum, token_id, mat):\n",
    "    for row_id in range(len(mat)):\n",
    "        if (mat[row_id][token_id] == 1) and (row_sum[row_id] >0): \n",
    "            decoded_message_index = token_id\n",
    "            # if the decoded message appears in another row, \n",
    "            # decrement the row_sum for that row \n",
    "            row_sum[row_id] = row_sum[row_id] - 1\n",
    "            if row_sum[row_id] == 1:\n",
    "                return row_sum, row_id\n",
    "            else:\n",
    "                print(\"Need to send more tokens!\")\n",
    "    \n",
    "def check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message):\n",
    "    \n",
    "    print(\"Row sum: \", row_sum)\n",
    "    print(\"Sent tokens: \", sent_token)\n",
    "    print(\"Previous decoded token index: \", prev_decoded_index)\n",
    "#    print(\"Next message to decode: \", next_message_to_decode_index)\n",
    "    print(\"\")\n",
    "\n",
    "    flag = 0\n",
    "\n",
    "    # Case 1. The token is either plaintext \n",
    "    \n",
    "    # The first conditions means it's plaintext since the token\n",
    "    # can be decoded without an xor operation \n",
    "    \n",
    "    if (row_sum[token_id] == 1 and sent_token[token_id]):\n",
    "        is_plaintext = sent_token[token_id].decode('utf-8')\n",
    "#        print(type(is_plaintext))\n",
    "        if is_plaintext.isalpha() or is_plaintext.isnumeric():\n",
    "                  \n",
    "            flag = 1\n",
    "            messg, indx = decode(sent_token, token_id)\n",
    "            decoded_message[indx] = messg\n",
    "            print(\"Decoded message:\", decoded_message[indx])\n",
    "            prev_decoded_index = indx\n",
    "                \n",
    "            updated_row_sum, next_row_id = update_dependencies(row_sum, token_id, mat)\n",
    "            next_message_to_decode_index, prev_decoded_index = get_index(next_row_id, mat, token_id) # other index in row that  = 1 other \n",
    "                                                                                # than decoded message\n",
    "            print(\"Flag: \", flag)\n",
    "            print(\"Updated row sum: \", updated_row_sum)\n",
    "            print(\"Sent tokens: \", sent_token)\n",
    "            print(\"\")\n",
    "            print(\"Next token to send: \", next_row_id)\n",
    "            check_dependencies(updated_row_sum, next_row_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "         \n",
    "    \n",
    "    # Case 2. The token has to be xor'd with another already decoded message in the row\n",
    "    \n",
    "    # The second condition means there is 1 dependency and\n",
    "    # we also have received the token so we can decode it.  1 dependency, if it's not plaintext implies\n",
    "    # we already decoded a message in this row, so we can xor it with the token \n",
    "    \n",
    "        elif  (row_sum[token_id] == 1 and sent_token[token_id]):      \n",
    "       \n",
    "            flag = 2\n",
    "            print(\"Xor\", token_id, prev_decoded_index)\n",
    "            print(\"Xor\", sent_token[token_id], decoded_message[prev_decoded_index])\n",
    "            print(\"Save Xor result to: \",next_message_to_decode_index)\n",
    "            result = xor(sent_token, token_id, decoded_message, prev_decoded_index)  \n",
    "            # token_id is index of the most recent token sent\n",
    "            # d_index is the index of the previous token sent that has already been decoded\n",
    "            decoded_message[next_message_to_decode_index] = result.decode()\n",
    "            print(\"Decoded message:\", decoded_message)\n",
    "#            prev_decoded_index = next_message_to_decode_index\n",
    "        \n",
    "            updated_row_sum, next_row_id = update_dependencies(row_sum, token_id, mat)\n",
    "            next_message_to_decode_index, prev_decoded_index = get_index(next_row_id, mat, token_id) # other index in row that  = 1 other \n",
    "                                                                                                        # than decoded message\n",
    "            print(\"Flag: \", flag)\n",
    "            print(\"Updated row sum: \", updated_row_sum)\n",
    "            print(\"Sent tokens: \", sent_token)\n",
    "            print(\"\")\n",
    "            print(\"Next message to decode: \", next_message_to_decode_index)\n",
    "            print(\"Next token to send: \", next_row_id)\n",
    "            check_dependencies(updated_row_sum, next_row_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "    \n",
    "    \n",
    "    # Case 3. We havent received the token yet. We need to get anohter token and check if it can be decoded\n",
    "    \n",
    "    # The only other way we can decode a token with dependency 1 which is not\n",
    "    # plaintext is if we have already decoded a message in that row\n",
    "    # In case 3 we have a row or token with 1 dependency but we have received the token yet\n",
    "    \n",
    "    elif (row_sum[token_id] == 1 and sent_token[token_id]==0):  \n",
    "        flag = 3\n",
    "        print(\"Flag: \", flag)\n",
    "        print(\"Updated row sum: \", row_sum)\n",
    "        print(\"Sent tokens: \", sent_token)\n",
    "        \n",
    "        token_id, sent_token, prev_decoded_index = get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index)  # Get another token\n",
    "        check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "        \n",
    "        \n",
    "    # Case 4. We havent found a row with 1 dependency so no tokens can be decoded.  \n",
    "    else:\n",
    "        print(\"We cant decode.  Send another token\")\n",
    "#        if flag > 0:\n",
    "        flag = 4\n",
    "        token_id, sent_token, prev_decoded_index = get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index)\n",
    "        check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "#        else:\n",
    "#            token_id, sent_token = get_token(sent_token, sent_token_count, encoded_message)\n",
    "#            check_dependencies(row_sum, token_id, sent_token)\n",
    "\n",
    "    print(decoded_message)\n",
    "\n",
    "def get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index):\n",
    "    # get a token\n",
    "    # check dependencies to determine if the token can be decoded\n",
    "    choice = input(\"To send an encoded message, enter a token id between 0 to 10 or type q to quit: \")\n",
    "    token_id = int(choice)\n",
    "    sent_token_count[token_id] = sent_token_count[token_id] + 1  # count number times each token sent\n",
    "    sent_token[token_id] = encoded_message[token_id]\n",
    "    print(\"Token sent:\", sent_token)\n",
    "    print(\"Number of times each token sent:\", sent_token_count)\n",
    "    return token_id, sent_token, prev_decoded_index\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    encoded_message = [b'\\x03', b'\\x17', b'3', b'\\x03', b'\\x08', b'$', bytearray(b'W'), b'-', b'$', b'\\x00', bytearray(b'd')]\n",
    "    num_tokens = len(encoded_message)\n",
    "    sent_token_count = [0]*num_tokens\n",
    "    sent_token = [0]*num_tokens\n",
    "    decoded_message = [0]*num_tokens\n",
    "\n",
    "    choice = 'y'\n",
    "    while choice !='q':      \n",
    "        print(\"\")\n",
    "        if choice == 'q':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Initial dependencies:\", row_sum)\n",
    "            prev_decoded_index = 0\n",
    "            token_id, sent_token, prev_decoded_index = get_token(sent_token, sent_token_count, encoded_message, prev_decoded_index)\n",
    "#            token_id = int(choice)\n",
    "#            sent_token_count[token_id] = sent_token_count[token_id] + 1  # count number times each token sent\n",
    "#            sent_token[token_id] = encoded_message[token_id]\n",
    "#            print(\"Token sent:\", sent_token)\n",
    "#            print(\"Number of times each token sent:\", sent_token_count)\n",
    "#            print(\"Initial dependencies:\", row_sum)\n",
    "             \n",
    "            next_message_to_decode_index = 0      \n",
    "            check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "\n",
    "#            decoded_mesg = check_dependencies(row_sum, token_id, sent_token, prev_decoded_index, next_message_to_decode_index, decoded_message)\n",
    "#            print(\"Decoded message: \", decoded_mesg)\n",
    "#            is_start_token = check_dependencies(row_sum, token_id, sent_token)\n",
    "            \n",
    "#            if (can_decode):\n",
    "#                print(\"We can decode this token\")\n",
    "#                messg, indx = decode(sent_token, token_id)\n",
    "#                decoded_message[indx] = messg\n",
    "#                print(\"Decoded message:\", decoded_message[indx])\n",
    "                \n",
    "                # After we decode a message we need to update all rows that depend on the decoded message\n",
    "                # i.e. we decrement each row sum by 1 if it contains the decoded message\n",
    "                \n",
    " #               updated_row_sum, next_row_id, d_index = update_dependencies(row_sum, token_id, mat)              \n",
    " #               e_index = get_index(next_row_id, mat, token_id) # other index in row that  = 1 other \n",
    "                                                                # than decoded message\n",
    " #               print(\"Most recent token sent:\", sent_token[next_row_id], \"Previous decoded message:\", sent_token[d_index])\n",
    " #               print(\"Updated row sum: \", updated_row_sum)\n",
    "                \n",
    "                # After updating all row sums, we check if we have received the tokens\n",
    "                # for all rows that have only 1 dependency\n",
    "                \n",
    " #               if sent_token[next_row_id] == 0:   # We dont have the token, so get another token \n",
    " #                   prev_decoded_token = sent_token[d_index]\n",
    "#                    print(\"We need to receive more tokens to decode.  Send token\", next_row_id)\n",
    "#                    next_token, sent_token = get_token(sent_token, sent_token_count, encoded_message)\n",
    "#                    print(\"Next token: \", next_token, \"Next row id: \", next_row_id)\n",
    "#                    if next_token == next_row_id:  # check if it is a token that matches a row with 1 dependency\n",
    "#                        sent_token[next_row_id] = encoded_message[next_row_id]\n",
    "#                        result = xor(sent_token, next_row_id, token_id) \n",
    "#                        decoded_message[e_index] = result\n",
    "#                        print(\"Just decoded token.  Update dependencies for rows in matrix containing message, \" e_index)\n",
    "#                        print(\"Decoded message:\", decoded_message)\n",
    "#                        updated_row_sum, next_row_id, d_index = update_dependencies(row_sum, e_index, mat)\n",
    "#                        can_decode = check_dependencies(updated_row_sum, e_index, sent_token)\n",
    "#                        if can_decode:\n",
    "#                            \n",
    "#                    else:\n",
    "#                        next_token = get_token(sent_token, sent_token_count, encoded_message)\n",
    "#                    continue\n",
    "#                else:\n",
    "#                    result = xor(sent_token, next_row_id, d_index)  \n",
    "#                    # token_id is index of the most recent token sent\n",
    "                    # d_index is the index of the previous token sent that has already been decoded\n",
    "#                    decoded_message[e_index] = result\n",
    "#                    print(\"Decoded message:\", decoded_message)\n",
    "#            elif token_id == 4:\n",
    "#                print(\"We received next token:\", sent_token[token_id], sent_token[next_row_id])\n",
    "#                result = xor(sent_token, token_id, next_row_id) \n",
    "#                decoded_message[e_index] = result\n",
    "#                print(\"Decoded message:\", decoded_message)\n",
    "#            else:\n",
    "#                print(\"We can't decode this token.  Get another token\")\n",
    "#                token_id, sent_token = get_token(sent_token, sent_token_count, encoded_message)\n",
    "#                 # (1) check dependencies or (2) send more tokens\n",
    "                 \n",
    "                \n",
    "#                    send_token(row_sum,token_id, decoded_message)\n",
    "    \n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875a743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
